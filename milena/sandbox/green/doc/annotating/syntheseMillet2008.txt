
Millet utilise un certain nombre de descripteurs (p 65, Chapitre 3)
pour l'annotation automatique. Son objectif est de formuler une
annotation automatique simple à partir de descripteurs de bas niveaux
qui permettent de réaliser l'opération en moins de 10 secondes.

L'auteur présente dans le chapitre 4, p 77 l'arbre de classification
et l'utilisation précise qu'il fait de ces descripteurs.


Reconnaissance des images de clipart versus photographies
Reconnaissance des images Noir & Blanc versus Couleur
Reconnaissance Interieur versus Exterieur
Autre reconnaissance cartes, photos, peintures.


               /---------Image------------\
               |                          |
               v                          v
  /-------+------+-------\        /-------+----------\
  |       |      |       |        |       |          |
  v       v      |       v        v       v          v
Carte  Clipart   |   Peinture  Couleur   N&B     N&B colorisé
                 |
                 v
          /----Photo----------\
          |                   |
          v                   |
    /----------\              |
    |          |              |
    v          |              v
Intérieur      |           Visages
               |
               v
     /-----Extérieur------\
     |                    |
     v                    v
  /-----\              /-----\
  |     |              |     |
  v     v              v     v
Jour   Nuit         Nature Urbain


Note:
-----
Lorsque d'un concept, on part de sa droite et de sa gauche, il s'agit en fait
de tests différents effectués en parallèles (ex.: Image, Photo, Extérieur).

Lorsqu'on aboutit à une bifurcation et qu'il ne s'agit pas d'un concept, cela
correspond à un seul test dont les résultats sont répartis dans des classes
différentes.

Fax
Magazine



ANNEXE 1 : SYNTHESE DESCRIPTEURS MILLET
=======================================

* RGB-64
--------
Chaque composante est quantifiée sur 4 valeurs (4x4x4 = 64), puis on construit
l'histogramme à 64 composantes.


* TSVal
-------
A partir de l'espace RGB d'origine, on effectue
la transformation. Attention les composantes ne sont pas quantifiées
de la même manière (18 valeurs pour la teinte [17 + 1 pour le
négatif], Val et S sont quantifiées sur 3 valeurs
chacunes. L'histogramme obtenu dans cet espace contiendra 162
composantes.

Val = max(R,G,B)
S   = [max(R,G,B) - min(R,G,B)] / max(R,G,B)

Si    R = max(R,G,B)
Alors T = 60 * (G-B) / [max(R,G,B) - min(R,G,B)]

Si    G = max(R,G,B)
Alors T = 60 * (2 + (B-R) / [max(R,G,B) - min(R,G,B)])

Si    B = max(R,G,B)
Alors T = 60 * (4 + (R-G) / [max(R,G,B) - min(R,G,B)])


* RGB-64-9
----------
L'image est décomposée en 9 sous images identiques, puis on applique le
descripteur RGB-64. L'histogramme obtenu est la concaténation des 9
histogrammes soit un histogramme résultant à 576 composantes.


* BIC
-----
L'image est quantifiée en 216 couleurs (RGB-216) 6 valeurs par couleur. On
distingue ensuite les pixels du bord des pixels intérieurs. Les pixels
intérieurs ont la même couleur que leurs 4-voisins. Un histogramme est crée
pour chaque groupe de pixels. Puis on concatène
les histogrammes en un seul de 432 composantes.


* LEP
-----
On construit une image de gradient avec un sobel 3x3, puis cette image est
seuillée à 100 et devient donc binaire. On étiquette les configurations
obtenues avec un masque 3x3 classique (convolution). Il existe 2^9
configurations possibles. On construit alors un histogramme à 512 composantes.

masque de convolution pour l'identification de la configuration:
001 002 004
008 256 016
032 064 128


* GABOR
-------
Très coûteux, la réponse de 24 filtres sur une image 300x300 est de l'ordre de
 1s. On utilise ici des filtres de taille 8x8.

F(x,y) = [1 / (2 PI sigma_x sigma_y)]
         * exp[(-1/2)(x^2/sigma_x^2 + y^2/sigma_y^2)] * exp[j2 PI Wx]

sigma_x et sigma_y sont des paramètres d'échelles.
W permet de changer l'orientation.

Il existe une formule pour trouver les coefficients des filtres une fois que
l'on a déterminé le nombre d'orientations et d'échelles utilisées. On ne
retiendra, en sortie de filtre, que la variance et l'énergie. L'auteur
préconise d'utiliser 6 directions et 4 échelles.


--------------GABOR---------MATLAB----------------------------------------------
function gb=gabor_fn(sigma,theta,lambda,psi,gamma)

sigma_x = sigma;
sigma_y = sigma/gamma;

% Bounding box
nstds = 3;
xmax = max(abs(nstds*sigma_x*cos(theta)),abs(nstds*sigma_y*sin(theta)));
xmax = ceil(max(1,xmax));
ymax = max(abs(nstds*sigma_x*sin(theta)),abs(nstds*sigma_y*cos(theta)));
ymax = ceil(max(1,ymax));
xmin = -xmax; ymin = -ymax;
[x,y] = meshgrid(xmin:xmax,ymin:ymax);

% Rotation
x_theta=x*cos(theta)+y*sin(theta);
y_theta=-x*sin(theta)+y*cos(theta);

gb=exp(-.5*(x_theta.^2/sigma_x^2+y_theta.^2/sigma_y^2)).*cos(2*pi/lambda*x_theta+psi);

http://matlabserver.cs.rug.nl/cgi-bin/matweb.exe
Gabor Filters. Tech. rep., 2002.
--------------GABOR---------MATLAB----------------------------------------------


* PROJECTION
------------
L'image est redimentionnée en 100x100. Un coup de Sobel 3x3, puis une
binarisation avec s=100. On considère les moitiées verticales puis
horizontales. Pour les moitiées verticales, on réalise la somme sur chacune
des lignes, on obtient alors un vecteur de taille 100.
Pour les moitiées horizontales, on réalise les sommes des colonnes. On obtient
alors un vecteur taille 100. Les 4 sous vecteurs obtenus peuvent être
concaténés pour former un unique descipteur de 400 composantes.



ANNEXE 2 : SYNTHESE CLASSIFICATION MILLET
=========================================


* Reconnaissance des images de clipart versus photographies
-----------------------------------------------------------

Construire l'histogramme de l'image, éliminer toutes les couleurs peu
représentées et ensuite les comptées. Moins de 50 couleurs / 256, c'est un
clipart, plus de 150 / 256 c'est une photographie. Entre les deux, indécision.
D'après l'auteur, le test n'est pas complètement fiable et peu être évincé, tout
dépend de la qualité de la compression des cliparts.

Diviser l'image en 16 imagettes (4x4), calculer la suite pour chaque imagette.
Trouver le maxima de l'histogramme (noté p)/ p = argmax H(x), x in [0,255].
Puis on calcule un sigma autour du pic.

sigma^2 = Sum(p-1,p-5) r(x) pour p > 250
sigma^2 = Sum(p+1,p+5) r(x) pour p < 005
sigma^2 = (1/2) (Sum(p-1,p-5) r(x) + Sum(p+1,p+5) r(x)) pour les autres p

r(x) = ((H(x)/H(p)) * (x-p))^2


Le descripteur de l'image entière est alors le maximum des 16 sigma^2. Si le
pic est resseré, c'est plutôt un clipart (< 5), sinon plutôt une photographie
(> 40). Le seuil est fixé à 15.



* Reconnaissance des images Noir & Blanc versus Couleur
-------------------------------------------------------

Achromatisme (en passant par TSVal)

si    |R - G| < s
et si |R - B| < s alors R ~ G ~ B
et si |G - B| < s

==> T   = -1
==> Val = (R + G + B)/3

L'auteur propose s = 0,03

Une image est dite Noir & Blanc (donc Achromatique) si + de 99% des pixels le
sont. Le test peut être appliqué aux images étiquetées comme des cliparts, ou
des photographies.


Faible saturation:

On établit l'histogramme de la saturation de l'image (0 à 255). Si plus de 95%
des pixels sont inférieurs à une saturation de 100, alors l'image est faiblement
saturée. Ce test ne s'applique sur les photographies, surtout pas aux cliparts.


Dominance de la teinte (image jaunie):

On construit l'histogramme de la teinte (0 à 255). On localise le maximum de
l'histogramme. Si + de 95% des pixels ont une distance < 20 du maximum, alors
l'image est considérée comme Noir & Blanc et on peut donner sa teinte dominante.
De plus il faut qu'au moins 50% des pixels soient faiblement saturés.

T = -1         Achromatisme
  0 <= T <  14 Rouge
 14 <= T <  29 Orange
 29 <= T <  45 Jaune
 45 <= T < 113 Vert
113 <= T < 149 Cyan
149 <= T < 205 Bleu
205 <= T < 235 Violet
235 <= T < 242 Rose, Magenta
242 <= T < 255 Rouge


  0 <= V < 82  Noir
 82 <= V < 179 Gris
179 <= V < 255 Blanc


Pour un pixel (S, Val)
si |184 - S| + |65 - Val| < |255 - S| + |125 - Val| alors marron sinon orange.

Et encore
si la teinte est jaune et Val < 80 alors vert sinon jaune.



* Reconnaissance Interieur versus Exterieur
-------------------------------------------

Utilisation des descripteurs LEP et RGB-64. Expérience avec un kpp ~ 80%. Puis
expérimentation avec un SVM ~ 90% de réussite. Finalement, inclusion dans le SVM
de LEP, RGB-64, TSVal-125, projection, Bic, Gabor.




* Localisation des visages
--------------------------

Une semaine d'apprentissage, 5 secondes pour leur localisation. Je ne suis pas
sûr que cette méthode soit pertinente pour notre contexte applicatif.



* Autre classification
----------------------

Utilisation de SVM et de tous les descripteurs possibles comme pour Interieur
versus Exterieur.
