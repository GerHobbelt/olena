I ARBORESCENCE
--------------

bench  ==> Comparaison d'algorithmes d'un point de vue temps d'exécution.
bug    ==> Bug rencontrés dans milena et archivés sous forme de programme.
build  ==> Répertoire d'exécution, non sauvé dans git.
demo   ==> Première version d'un algorithme pour voir son comportement.
doc    ==> Documentation tex ou code minimal pour de petits exemples.
exp    ==> Version avancée des algorithmes pour traitées les bases de données.
mln    ==> Partie mise en librairie milena des différents travaux.
tests  ==> Tests unitaires sur certains algorithmes.
tools  ==> Découpage de certains algorithmes pour mieux les tester séparément.
use    ==> Test de compilation, code minimal pour compiler un élément.

II COMPILATION
--------------

L'unité minimale de code choisie est le répertoire.
Donc aller dans le répertoire qui nous interesse,
par exemple, green/demo/annotating/hsv et lancé le make

#:~/git/olena/scribo/sandbox/green$cd demo/annotating/hsv
#:~/git/olena/scribo/sandbox/green/demo/annotating/hsv$ make -f Makefile.am

Cette opération créé dans build le répertoire de compilation
green/build/demo/annotating/hsv. Dans ce répertoire aura été copié un
Makefile et tous les fichiers qui ne sont pas des sources. Par
exemple, des fichiers de calibration comme gaussian.sh (pour vérifier
la mire du filtre de gaussienne) ou de la documentation à la sauvette
sous forme de fichiers textes jetés à la va vite dans le répertoire
pour ne pas perdre l'information recherchée. En l'occurence, ici, il
n'y a rien à copier. Rendons-nous dans le répertoire de compilation et lançons
le makefile.

#:~/git/olena/scribo/sandbox/green/demo/annotating/hsv$
#:cd ../../../build/demo/annotating/hsv
#:~/git/olena/scribo/sandbox/green/build/demo/annotating/hsv$ make clean all

L'exécutable est généré par le makefile, il porte le nom du
répertoire.  Si il y a besoin de mettre à jour le makefile, le faire
dans le répertoire des sources en éditant Makefile.am, puis en
régénérant le Makefile dans le répertoire d'exécution par la commande
make -f Makefile.am depuis le répertoire source.


III MAKEFILE
------------

Les makefiles utilisés sont tous les mêmes avec quelques variables
dont le contenu change dans leur partie en-tête.

Pour chaque répertoire, le makefile doit savoir si le chemin courant
est un répertoire de compilation ou un répertoire de source. Pour les
identifier, il a recours à un pattern qui malheureusemnt fait
intervenir le nom de la branche de développement (bench,demo,bug,exp ...).

SOURCE_PATTERN= green/demo
BUILD__PATTERN= green/build/demo

Si un makefile ne fonctionne pas, il faut vérifier ceci en premier
lieu. Ici, le makefile doit être situé dans la branche démo.

Autre élément à savoir, la compilation nécessite d'inclure la
librairie milena, ainsi que les développements propres en vu de leur
intégration futur dans milena, ceci est fait par un jeu d'INCLUDES1
et INCLUDES2.

INCLUDES1= -I$(HOME)/git/olena/scribo/sandbox/green
INCLUDES2= -I$(HOME)/git/olena/milena
INCLUDES=  $(INCLUDES1) $(INCLUDES2)

Suivant l'allure du compte où l'on exécute les makefiles, il faut
revoir le chemin pour trouver des deux répertoires.

Enfin, les options de compilations ne sont pas toujours les mêmes. Les
trois lignes possibles sont toutes présentes et seule celle qui est
utilisée n'est pas commentée. Typiquement, dans la branche de
développement démo où les perfomances ne sont pas le problème, on
compilera avec tout le matériel pour utiliser gdb et sans
optimisation. A l'inverse, dans la branche d'expérimentation, où le
code a déjà été testé, on cherche à aller vite car on exécute ce code
sur de nombreuses images. Dans cette optique, pas de débugage, pas de
traçage, optimisation conséquente.

CXXFLAGS= -ggdb -O0 -Wall -W -pedantic -ansi -pipe $(INCLUDES)
#CXXFLAGS= -DNDEBUG -O1 -Wall -W -pedantic -ansi -pipe $(INCLUDES)
#CXXFLAGS= -DNDEBUG -O3 -Wall -W -pedantic -ansi -pipe $(INCLUDES)

Une dernière dernière information, dans le cadre des développements
exp, et tools, on utilise la librairie boost soit pour la
virtualisation du filesystem, soit pour le formatage des fichiers text
(réalisation de colonnes, mettre des entiers sur un certain nombre de
caractères). Une ligne de chargement des librairies peut apparaitre donc.

LOADLIBES= -lboost_filesystem

On retrouvera les includes suivantes dans les sources:

#include <boost/format.hpp>
#include <boost/filesystem.hpp>


IV CHEMINS DES IMAGES
---------------------

Toutes les images ont toujours été locales sur mon ordinateur. La
politique a toujours été d'utiliser un fichier img_path pour coder les
chemins des images.  Les chemins étant plutôt long, j'ai toujours eu
tendance à faire en sorte qu'ils soient compilés en dur (sauf pour la
partie développement tools qui est vraiment voué à donner des
exécutables indépendants et génériques). Le fichier mln/img_path.hh
code la position de toutes les images dans mon arborescence. Il faudra
donc veiller à changer tous les chemins pour les adapter au compte
dans lequel on voudra reprendre le code. Dans le code, les références
aux positions des images sont faites via des macros.

Toutes les images sont située dans git/img. En règle générale, je ne
traite que des images au format .pgm, .pbm et .ppm. Il m'arrive
fréquemment de dumper des images au format .sh (gnuplot shell
image). Pour la branche tools, nous avons utilisé les dumps de milena
comme format de transfert d'un utilitaire à un autre. Les images sont
classées suivant leur provenance. Nous avons tout d'abord la base
OLENA (copie des images de tests milena), la base INIM (très peu
utilisée voire jamais), la base ICDAR (très utilisée, surtout dans
exp), la base AFP (très utilisée dans exp) et les bases ANNOTATING1 et
ANNOTATING2 (pas très utilisées ni l'une, ni l'autre).

La plus part du temps, sauver les résultats dans le répertoire
d'exécution courant est largement suffisant. Parfois, il est
nécessaire de sauvegarder de grosses quantités d'informations et de
les classer comme dans la branche de développement exp. C'est pour
cela, qu'un certain nombre de macros définissent des endroits pour
sauvegarder les résultats lors d'expérimentation de grande ampleur sur
toute la base ICDAR ou AFP.


V GNUPLOT SCRIPT SHELL IMAGE FORMAT
-----------------------------------

J'abrège le nom du format par gnuplot shell format. En fait, c'est un
format d'image particulier qui a besoin de gnuplot pour être lu. Il
est donc compatible avec aucun viewer si ce n'est gnuplot, mais a la
caractéristique d'afficher tous les points de manière visible. Par
ailleurs, comme il s'agit d'un script gnuplot il permet d'insérer très
facilement une fonction pour visualiser les données autrement (par
exemple, changer d'espace: HSL, HSV). Le fichier tire son nom de la
façon dont il fonctionne. C'est un script shell qui fait un appel à
gnuplot et lui passe le jeu de données directement à partir de ce même
fichier, pas besoin de faire appel à un autre fichier. Une fois
généré, le fichier doit être modifié pour avoir les permissions
d'exécution (chmod 755 gnuplot_shell_file.sh). Comme je trouve le format
extrêmement pratique, il se retrouve preque partout dans mes sources.


VI HISTOGRAMMES
---------------

Un des travaux demandés par théo est la réalisation d'une librairie
d'histogramme permettant de fournir un résultat sous forme d'image.
L'intérêt est ensuite de pouvoir filtrer directement ces histogrammes
par les algorithmes de milena, ou encore d'étudier les valeurs
caractéristiques par d'autres accumulateurs. Les codes réellement
utilisés sont histo1d et histo3d RGB. Tous les autres codes sont très
expérimentaux. Notemment, le code HSL demande de quantifier l'espace
de comptage puisqu'il est décrit sous la forme de triplets de float
(les autres sont inférés). Néanmoins, le code est à conserver car il
contient une séquence d'appels pour les routines permettant de
considérer la dimension de la teinte comme circulaire.

Après réflexion, le code des histogrammes et tous les accumulateurs
qui en découlent devraient être rangés dans l'espace de nommage
mln::accu::histo. Cela permettrait de ne pas parasiter mln::accu::stat
avec tous les éléments propres aux histogrammes et de ne pas faire un
espace de nommage à rallonge en introduisant histo dans stat. Donc
mln::accu::stat semble être une bonne postion pour le rangement final
du code relatif aux histogrammes.


a) version 1d

* mln/accu/stat/histo1d.hh: Accumulateur histogramme image1d.
* use/accu/stat/histo1d: Code minimal utilisant un histogramme 1d.
* tests/accu/stat/histo1d: Tests unitaires sur l'histogramme 1d.


b) version 2d

* mln/value/rg.hh: Définition du type vectoriel 2d rouge/vert (RG).
* use/value/rg: Exemple de code pour l'utilisation de rg.

* mln/fun/v2v/rgb_to_rg.hh: Transformation de l'espace RGB vers l'espace RG.
* use/fun/v2v/rgb_to_rg: Exemple de code pour l'utilisation de rgb_to_rg.

* mln/accu/stat/histo2d.hh: Accumulateur histogramme image2d.
* use/accu/stat/histo2d: Code minimal utilisant un histogramme 2d.


c) version 3d RGB


* mln/fun/v2v/rgb8_to_rgbn.hh: Diminution de la quantification (n < 8 bits).
* use/fun/v2v/rgb8_to_rgbn: Exemple de code pour l'utilisation de rgb8_to_rgbn.

* mln/accu/stat/histo3d_rgb.hh: Accumulateur histogramme image3d RGB.
* use/accu/stat/histo3_rgb: Code minimal utilisant un histogramme 3d RGB.


d) version 3d HSL

* mln/accu/stat/histo3d_hsl.hh: Accumulateur histogramme image3d HSL.
* use/accu/stat/histo3_hsl: Code minimal utilisant un histogramme 3d HSL.
* tests/accu/stat/histo3d_hsl: Tests unitaires sur l'histogramme HSL 3d.

Le code HSL ne compile plus car l'interface liant la transformation du
domaine et la fonction fold a changée. Je n'ai pas le temps de
regarder plus avant.


VII SAUVEGARDE FORMAT GNUPLOT SHELL
-----------------------------------

Ce travail est personnel. Ces développements m'ont été tellement
utiles que je ne regrette pas l'investissement effectué. L'idée est de
pouvoir avoir un format d'image en écriture lisible. J'ai pris celui
de gnuplot, ce qui permet en plus de pouvoir "sucrer" la présentation
des données à loisir. Les images sont plus lourdes car le codage est
textuel et un peu plus "verbose" mais se compresse aisément par
n'importe quel algorithme type huffman (tous les archiveurs en possède un).

* mln/io/plot/save_image_sh.hh: Librairie de sauvegarde au format gnuplot shell.
* use/io/plot/save_image_sh: Code simple d'utilisation de la sauvegarde.
* tests/io/plot/save_image_sh: Tests unitaires sur l'export.



VIII VISUALISATION HISTOGRAMMES 3D
----------------------------------

Les histogrammes sur lesquels nous sommes amenés à travailler sont en
3d.  Nous étudions des images couleurs dans l'espace RGB, donc
l'histogramme dans cet espace possède 3 dimensions (une par axe, R, G
et B) et la cellule désignée par cette position RGB renfermera le nombre
de pixels de l'image ayant exactement cette couleur. Il est très
difficile de bien visualiser ces images, car elles sont en 3d. Gnuplot
nous donne qu'une aide très limitée, car il faut afficher 3 axes et la
force de la cellule, ce qui fait en fait quatre informations à
afficher. Il est possible de jouer avec les couleurs, mais il n'y a
pas de représentation très utile, on peut afficher le nuage des
couleurs pour percevoir sa forme générale, mais l'interprétation ne
peut pas vraiment aller plus loin. C'est pourquoi, nous proposons une
représentation plus pertinente. C'est Théo qui a roulé sa bosse en
classification qui a developpé ce genre de technique, je ne fais que
réutilliser les mêmes analyses en beaucoup moins fins que ce qu'il a
déjà pu développer par ailleurs.

La première idée est de gommer une dimension, et c'est possible de le
faire car dans une image RGB, souvent l'axe bleu est fortement
correllé avec l'axe vert. Cela dépend beaucoup de la formation des
images et pour des images synthétiques, il n'y a aucune raison que
ce soit le cas. C'est juste une propriété qui s'applique pour les
images naturelles. La forte corrélation obtenue ne veut pas dire qu'il
y a exactement les mêmes informations, juste que dans l'ensemble on
note une relative redondance (du point de vue statistique). Pour t'en
convaincre, tu peux regarder sous gimp, les histogrammes sur les
différents canaux et tu observeras qu'il y a deux canaux (le vert et
bleu) pour lesquels les histogrammes sont presque identiques.

La dernière étape est de réaliser un traitement sur la dimension qui a
été supprimée. Par exemple, sommer toutes les valeurs rencontrées ou
ne retenir que la valeur max ...

Le fichier display_histo.hh joue le rôle de front hand pour les
routines de visualisation. Il a pour rôle d'initialiser, d'instancier,
de coordonner la chaine de visualisation. Le fichier project_histo.hh
décrit les algorithmes au coeur de la visualisation, comment est
construite concrêtement l'information que l'on visualise à la fin.

Nous avons construit 3 sortes de projecteurs. Le premier va sommer le
long de l'axe bleu les différentes informations
rencontrées. Globalement, cela signifie, que plus il y a de pixels
dans le sous espace (red=v1,green=v2) avec pour chaque pixel
rencontrés des valeurs de bleu différentes, plus le nombre construit
sera grand. Sur cette information, on fera passer un logarithme pour
diminuer les pics et ne faire ressortir visuellement que les
informations les plus saillantes. En dernier lieu, on rescalera les
valeurs obtenues pour utiliser pleinement la dynamique d'une image de
256 niveaux de gris. La visualisation obtenue nous donne un aperçu de
la densité de l'espace des couleurs. On observera en très lumineux les
endroits de forte population de couleurs et en presque noir l'absence
de couleur dans l'image pour cette portion de l'espace RGB.

Les autres techniques de visualisation sont des variantes du même
traitement que nous allons decrire. La chaine de base consiste à
parcourir la dimension bleu pour chaque point de l'espace rouge/vert
(comme dans la première technique). Cette fois-ci, ce n'est plus la
somme qui nous intéresse, mais la couleur la plus représentée. On va
faire un max des valeurs obtenues en parcourant l'axe bleu. Une
première version rapportera la position bleue qui rassemble le plus de
pixels. Une seconde version remplacera cette position bleue par un
label associé à une segmentation déjà effectuée dans cet espace.

La dernière technique modifie la version précédente de la manière
suivante: Nous sommes toujours interessé par le max, mais on va remplacer
cette information directement par la couleur reconstituée (nous sommes
sur un point particulier de l'espace red/green donc red et green sont
connus, et on vient d'obtenir la valeur bleue la plus représentée, on
utilisera cette valeur pour former une couleur RGB). A l'issu du
processus, on obtient donc une image couleur. L'information obtenue
ici, n'est plus la densité de l'histogramme, mais plutôt la couleur la
plus représentée à cet endroit. La toute première technique et celle-ci
sont complémentaires pour la bonne visualisation d'un histogramme
3d. Si l'on dispose d'une segmentation de l'espace des couleurs, on
peut trouver le label associé au bleu prédominant et récupérer dans
une palette de couleur annexe la couleur associée au label.

* mln/display/dispay_histo.hh: Front hand pour les routines de projection.
* mln/display/project_histo.hh: Les algorithmes de visualisations.

Le travail dans use ne représente que deux routines sur six de
display_histo.  Par manque de temps, je ne fais pas le reste de
manière à insister sur d'autres points documentaires plus
importants. Le cadre est en place et les autres routines plus
sophistiquées faisant intervenir la segmentation de l'histogramme
peuvent être tirées de tools/labeling/regmax par exemple.

* use/display/display_histo: Visualisations des histogrammes.


IX KMEANS
---------

Ce travail m'avait été demandé par théo. Je le laisse inachevé, quelque part
perdu pendant l'optimisation du code et sa transformation en canevas.


a) Première implémentation avec matrices et vecteurs

Cette version est bien documentée et permet de mieux comprendre les autres
versions. Par ailleurs, elle n'est pas spécialement optimisée ce qui fait
qu'elle colle davantage au modèle de l'algorithme kmean traditionnel.

* mln/clustering/k_mean.hh: Première implémentation avec matrices et vecteurs.
* use/clustering/k_mean:  Code minimal utilisant cette première implémentation.
* tests/clustering/k_mean: Tests unitaires sur la permière version.


b) Seconde implémentation avec image en 1d

Cette seconde version intègre une optimisation testée par théo il y a
longtemps. Je me demande si ce n'étais pas pendant sa thèse qu'il
avait travaillé sur cette version. Bref, dans la mesure où
l'optimisation passe par la création d'un histogramme, cette version
devient dépendante des histogrammes réalisés plutôt (il est aussi
dépendant de la sauvegarde au format gnuplot shell). L'idée générale
de l'optimisation est de ne plus raisonner sur l'image, mais sur
l'histogramme. Car à un moment donné, la classification ne tient
compte que de la valeur du pixel en intensité (pas de ses coordonnées
dans l'image). Donc tout pixel de même intensité sera classé de
manière identique. D'où l'intérêt de travailler avec les
histogrammes. Les limites de cette optimisation se trouvent dans la
taille des histogrammes. L'optimisation marche à merveille pour de
faibles quantifications (8 bits c'est parfait). Par contre, lorsque
l'on passe à un histogramme couleur, la taille de l'histogramme
devient problématique et peut dépasser la taille de l'image. Cette
optimisation n'a alors plus aucun sens.

* mln/clustering/kmean1d.hh: Implémentation 1d avec des images.
* use/clustering/kmean1d : Code minimal utilisant cette seconde implémentation.
* demo/clustering/kmean1d : Demonstrateur.

La visualisation de la convergence des moyennes, générée par le
démonstrateur, n'est pas très lisible. La lecture textuelle du fichier
gnuplot shell (mean_cnv.sh) permet d'interpréter ce qui se passe, par
contre le graphique est à refaire.


c) kmean2d

Cette troisième version est identique à la seconde, sauf qu'elle
permet de faire la classification dans un espace à deux
dimensions. Malheureusement, un tel travail dans cet espace coûte
beaucoup plus cher à l'exécution.

* mln/fun/v2v/rg_to_rgb.hh: Transformation de l'espace RG vers l'espace RGB.
* use/fun/v2v/rg_to_rgb: Exemple de code pour l'utilisation de rg_to_rgb.

* mln/clustering/kmean2d.hh: Implémentation 2d avec des images.
* use/clustering/kmean2d : Code minimal utilisant cette seconde implémentation.
* demo/clustering/kmean2d : Demonstrateur.

La visualisation de la convergence des moyennes est cette fois-ci
complètement aboutie. Le fichier semble avoir quelques soucis, il
manque des lignes dans le splot initial, en remettre pour qu'il y en
ait autant que les blocs de données. L'espace des couleurs étant le
bicanal r/g, on peut visualiser sur une troisième dimension
l'évolution des centres dans l'espace initial. L'effet est très réussi
et aussi très parlant. Chaque run, correspond alors à une trajectoire
particulière. L'affichage des variations des variances a été rénové et
est lui aussi beaucoup plus lisible.


d) kmean3d

Cette quatrième version est la copie conforme de la version
précédente. Les problèmes de visualisation sur les fichiés générés
sont les mêmes. L'affichage des convergences est identique. Le recours
à une dégradation de l'image d'entrée est impérative pour avoir des
temps encore acceptables.

* mln/clustering/kmean3d.hh: Implémentation 3d avec des images.
* use/clustering/kmean3d : Code minimal utilisant cette quatrième impl.
* demo/clustering/kmean3d : Demonstrateur.


e) kmean aplati

Cette cinquième version est très spéciale. Elle doit permettre de
gagner du temps d'exécution. Le concept est simple au départ, tout
écrire d'un seul tenant. L'exercice est fastidieux et difficile
(intellectuellement). Une fois fait, il faut réfléchir à ce qui peut
être mis sous forme de canevas. Par exemple, la manière de calculer
les distances peut être une information paramétrable. Cela pemettrait
de faire un benchmark in situ. La transcription actuelle compile. Elle
n'intègre pas tous les outils de debuggage que nous pouvions avoir sur
les autres versions. Par ailleurs, comme le code est réuni en une
seule fonction, nous avons pour l'instant une seule sortie, l'image de
labels de la classification réalisée. A partir de cette image, nous
pouvons en reconstruire d'autres. Il manque quand même la possibilité
d'observer les convergences. Le travail était en cours, à prendre donc
avec beaucoup de pincettes. La dernière exécution house.ppm, 3
centres, 10 itérations et 10 runs fonctionne parfaitement sur les
premiers runs puis l'affichage s'emballe sans que l'on y comprenne
rien. Un dump dans un fichier révèle le non appariement de certaines
traces (entering/exiting). Une piste à suivre est la sortie anticipée
d'une de mes boucles sans pour autant fermer une trace ... ???

* mln/clustering/kmean_rgb.hh: Implémentation 3d avec des images.
* use/clustering/kmean_rgb : Code minimal utilisant cette quatrième impl.
* demo/clustering/kmean_rgb: Utilisation de la version aplatie.


f) optimisation possible

Le calcul des distances entre les points et les différents centres
peut être réalisé par des transformées. Certes, les distances ne seront
pas les mêmes que la distance euclidienne, mais elles s'en approchent
et cela constitue très certainement une très bonne approximation pour
l'objectif que nous cherchons à atteindre. Le but de ce benchmark est
de regarder quel type de transformation est le plus rapide pour
arriver à nos fins en fonction des données d'entrée. Cette
optimisation n'a pas encore été intégrée dans le code, et reste une
piste à exploiter.

* bench/clustering/distance: Comparaison algorithmes d'évaluation des distances.

Une routine du benchmark ne compile plus. Il semble qu'il y ait un
mauvais appel à la fonction at_ dans la routine
influence_zone_geodesic.hh ligne 127. Le but du benchmark est de
tester les distances en 2d et 3d pour des voisinages différents (c04,
c08, c06, c18, c26) sur les routines distance euclidienne classique,
zone d'influence geodesique et zone d'influence "front". La première
serie de test vise à garder une taille d' image constante et
d'augmenter le nombre de centres pour voir comment se comporte les
algorithmes et la seconde serie, vise à garder un nombre constant de
centres et à agrandir progressivement l'image. Attention, le benchmark
essaye d'être assez exhaustif et donc se paye par un temps d'execution
assez long. Les différents fichiers générés reprennent les différents
tests effectués et montrent l'évolution du temps de calcul suivant la
progression du paramètre observé (taille de l'image ou nombre de
centres).


X REGIONAL MAXIMA
-----------------

Pour cette partie, le temps a commencé à s'accélérer, ce qui fait
qu'il n'y a plus de tests unitaires. Par ailleurs, comme la
fonctionnalité n'a pas été pensée comme un élément de la librairie, il
n'y a donc pas non plus de répertoire "use" à cet effet.


a) Segmentation basé sur le watershed

Cet exemple essaye une première méthode de filtrage de
l'histogramme. A noter elle ne compile pas. Elle eu compilé dans le
temps, mais le source a été tellement remanié que sa reconstruction
doit régler encore quelques détails.  Sa compilation n'a pas vraiment
d'intérêt en soi, seule la démarche compte ici.  Le temps me manque et
je ne persisterais pas à essayer de le faire compiler à tout prix. D'autres
sources sont beaucoup plus intéressant. Nota, gaussian.sh est un gnuplot
script shell qui sert à calibrer le filtrage de l'histogramme. Il permet
de déterminer visuellement la taille de la fenêtre win utilisée lors de la
convolution en fonction d'un écart type sigma donné.

* demo/labeling/watershed: Demonstrator de la segmentation d'un histogramme.


b) Second essai avec les regional_maxima

Le programme actuel ne compile pas non plus. Il n'est pas d'une grande
importance, alors du coup je le laisse tel quel. Il a servi a
plusieurs choses, en premier à tester les regional_maxima mais en
dernier lieu surtout à tester le filtrage par attribut (volume) qui
semblait avoir quelques soucis.  A l'heure d'aujourd'hui, je ne peux
toujours pas dire s'il fonctionne convenablement ou non, il semble que
parfois des anomalies se produisent à ce niveau, mais elles peuvent
aussi bien être générées par un problème interne à mon programme.

* demo/labeling/regional_maxima: Testeur du filtrage par attribut de volume.


c) Déplacement du programme b) dans exp.

Même programme que b) mais qui compile.

* exp/labeling/regional_maxima: Testeur du filtrage par attribut de volume.


d) Sources importantes ==> regional_maxima

Il y avait une autre version des regional_maxima ou toute la chaine était
présente, si j'avais davantage de temps, je l'aurais réecrite. Il semble
qu'elle se soit perdue lors de la migration de SVN vers GIT. Aucune importance.
Les outils "up to date" sont ceux dont les sources sont dans tools. La classe
outil représente des binaires un peu plus travaillé au niveau de l'interface
texte, en gros ils prennent plein de paramètres et génèrent des résultats
intermédiaires. Chaque outil à son usage ...


Ce qu'il faut savoir sur l'outil histo. Tout d'abord le programme
prend 7 ou 8 arguments et c'est le dernier qui est optionnel. Les
arguments sont l'image couleur à partir de laquelle on veut extraire
l'histogramme couleur (3d), le degré de quantification que l'on veut
utiliser (sous échantillonnnage de l'image), le chemin de l'image
couleur quantifiée résultante après analyse, le chemin de
l'histogramme produit (réutilisé par les autres outils), la
visualisation rouge/verte de l'histogramme (brute) et la visualisation
augmentée de ce même histogramme avec les maxima dessus. Se reporter à
la documentation des histogrammes pour avoir plus d'information sur ce
sujet. Le dernier paramètre optionnel est un masque à appliquer sur
les pixels de l'image d'entrée. La chaine de traitement de l'outil,
commence par sous échantillonner l'image en n bits, n < 8, puis
construit l'histogramme 3d à partir des pixels présents dans le masque,
si ce dernier existe et enfin sauvegarde des résultats et des images
servant à la visualisation.

* tools/labeling/histo: Construction de l'histogramme.


Ce qu'il faut savoir sur l'outil de filtrage de l'histogramme. Tout
d'abord, il prend en paramètre 6 arguments obligatoires. Les arguments
sont la quantification utilisée par l'outil de création de
l'histogramme, le chemin de l'histogramme à filtrer, le seuil utilisé
pour le filtrage (c'est le volume minimal en dessous duquel
l'information est jugée comme du bruit et donc ne doit pas passer), le
chemin de l'histogramme filtré, le chemin de la projection en densité
de l'histogramme et le chemin de la projection en couleurs
majoritaires de l'histogramme. Se reporter au chapitre sur la
visualisation pour comprendre les différentes projections. Le filtrage
est un traitement très simple, il applique uniquement l'algorithme
morphologique d'ouverture sur les attributs de volume. Imagine un
histogramme en 1d, l'attribut de volume est alors la surface sous la
courbe de l'histogramme. Une ouverture volumique consiste à supprimer
tous les pics ayant un volume inférieur au seuil. Cela fonctionne très
bien en général, toutefois, il y a des cas où les informations
retournées ne sont pas celles attendues. Concrêtement, des composantes
de volume inférieur au seuil sont retrouvées plus loin dans la chaine
de traitement, ce qui contredit l'usage de l'ouverture
morphologique. Il est difficile de définir ce qui se passe vraiment,
il est possible qu'il y ait un bug ou simplement que le reste de ma
chaine induise quelque fois ce résultat étrange. Honnêtement, je ne
sais pas ce qui se passe. Le cas n'arrive pas fréquemment, donc il est
très difficile d'isoler l'erreur.

* tools/labeling/opening: Filtrage de l'histogramme.


Ce qu'il faut savoir sur l'outil de labellisation. Tout d'abord, il
prend 11 arguments dont le dernier est optionel. Les arguments sont
l'image originale (nécessaire pour calculer la couleur moyenne des
labels ==> réalité augmentée), la quantification utilisée
précédemment, l'image préalablement quantifiée, l'histogramme
original, l'histogramme filtré, le voisinage sur lequel effectué les
opérations (c6, c18 ou c26), l'histogramme segmenté en 3d, la
projection red/green associée, la colormap, l'image reconstruite des
moyennes associé à chaque label et éventuellement un fichier décrivant
les statistiques associés aux labels (couleur moyenne associé au
label, plus nombre de pixels concernés dans l'image, plus pourcentage
absolu et pourcentage sans tenir compte du fond). Le seul appel
intéressant est la labellisation de l'histogramme filtré qui produit
une image 3d de label. Tout le reste est de la tuyauterie pour faire
de la rélatité augmentée. Par exemple pour formée l'image des moyennes
associées à chaque label, il est nécessaire de construire l'image 2d
des labels qui fait intervenir elle-même l'image d'entrée quantifiée
et l'image originale. Idem pour la construction de la
colormap. L'outil segmente l'histogramme filtré par la détermination
des maxima régionnaux, autrement dit des zones de très fortes
densités. Ces zones sont en général très petites, quelques pixels pas
plus. C'est pourquoi l'outil suivant va nous servir à les étendre un
peu.

* tools/labeling/regmax: Segmentation de l'histogramme.


Petite suprise désagréable, l'outil iz ne compile plus. La raison en
est toute simple, il y a eu du mouvement dans les fonctions
mln::transform::influence_zone_geodesic(). Un revamp un peu violent,
avec une version
mln::transform::influence_zone_geodesic_saturated(). J'ai corrigé le
changement d'appel, mais cela ne suffit pas. Dans la méthode
mln::transform::influence_zone_geodesic_fastest(), l.127, tu utilises
la méthode at() pour une image 2d et là pas de chance, moi j'utilise
cet algorithme pour une image de labels 3d (nous sommes dans un espace
RGB quantifié en n bits, n < 8). Je ne veux surtout rien détruire dans
scribo, donc je te laisse effectuer les changements qui s'imposent et
je continue la documentation.

Ce qu'il faut savoir sur iz. Tout d'abord cette routine prend 12
arguments dont le dernier est optionel. Les arguments sont
l'histogramme labelisé par l'outil précédent, la profondeur utilisée
pour l'influence par zone géodésique (0 signifie l'infini), puis vient
le voisinage 3d utilisé pour la propagation, puis l'image initiale,
puis le degrée de quantification utilisé par tous les outils, puis le
dump de l'histogramme, la colormap (utilisée pour la projection r/g
avec segmentation, puis l'histogramme labelisé après propagation nommé
iz et enfin la projection r/g, l'image reconstruite à l'aide des
moyennes des classes et le fichier de statistiques intégrant la
propagation des classes. La propagation a pour vocation d'agrandir les
classes obtenues jusqu'à maintenant. C'est une information que l'on
voit bien avec les changements dans les projections r/g.

* tools/labeling/iz: Propagation des classes par zone d'influence.


Comme le paramétrage est difficile, il est conseillé de relire les
scripts des jeux de tests qui coordonnent l'appel de ces routines avec
une sucession de paramètres cohérents. Je sais ce que tu vas me dire,
c'est mal, il ne faut pas mettre d'images sur le dépot git. Dans
l'absolu, je suis d'accord, mais aujourd'hui, le code iz est cassé et
rejouer ces tests peut prendre énormément de temps, donc par facilité,
je me contente des résultats que j'avais archivé et que tu seras
content de trouver pour en inclure une partie dans ton rapport.

Tout d'abord un jeu de répertoire de test en instance d'être lancé. Le
répertoire porte le nom de l'image sur laquelle est effectué le
test. On y trouvera l'image originale pleine résolution, et les deux
masques de gradient fin et un peu plus épais. Pour faire le test, il
suffit d'écrire le script comme dans doc/labeling/mp00307.

* doc/labeling/mp00215c
* doc/labeling/mp00234c
* doc/labeling/mp00248c
* doc/labeling/ta00031c
* doc/labeling/ta00083c


Puis, nous avons les tous premiers tests qui ont servi pour déterminer
la quantification à utiliser et la méthode de propagation (infinie ou
saturée). Il y a longtemps, pour ces tests, je disposais d'une chaine
complète mais cette dernière c'est perdu dans la migration entre svn
et git. Il n'y a donc pas de script shell qui lance les outils, par
contre il existe un fichier de synthese qui explique exactement ce qui
a avait été lancé et avec quels paramètres, histoire de pouvoir rejouer le test.

* doc/labeling/cmp_method: Test sur le type de propagation à utiliser.
* doc/labelling/cmp_quant: Test sur la quantification a utiliser.


Puis, nous avons les tests effectués à l'aide d'un script. Lire les
scripts pour situer correctement les binaires outils utilisés. Le
premier jeu test avait pour but d'étudier la combinatoire des options
et de choisir ensuite les paramètres qui vont bien. Il n'y a pas de
certitude complète en la matière. Lire attentivement le fichier
synthèse. Tout ces éléments ont été validés par théo. Je ne me rapelle
plus du détail, mais j'ai rédigé tout ce que je pouvais. Le dernier
répertoire n'a pas de fichier synthèse, je pense que l'étude était du
même gabarit que le test précédent. J'en étais à tester la routine sur
un maximum d'images pour voir si le jeu réduit de couleurs obtenues
correspondait à nos attentes ou non. Les paramètres stables sont à
rechercher dans les derniers répertoires mp00042c et mp00307c.

* doc/labeling/mp00307c_bis: Test sur un grand nombre de combinaisons.
* doc/labeling/mp00411c: Test sur l'altération des statistiques.
* doc/labeling/mp00042c: Test sur la representativité des couleurs trouvées.
* doc/labeling/mp00307c: Test sur la representativité des couleurs trouvées.


XI AUTRES ASPECTS DOCUMENTAIRES
-------------------------------

Ces exemples de codes sont livrés tels quels sans aucune documentation
de ma part. Si tu as besoin de quelque chose, sert toi, tu les
remanieras à ta sauce. Il n'y a pas de raison de les documenter, se
serait disperser mes efforts vainement.

* doc/examples/accu_color: Petit programme pour se bidouiller avec la couleur.
* doc/examples/frac: Librairie pour manipuler des fractions sous milena.
* doc/examples/hello_milena: Petit exemple allant avec la doc de milena.
* doc/examples/hello_world: Test de la plateforme c++.
* doc/examples/io: Rien de vraiment intéressant dans l'état actuel.
* doc/examples/learn_milena: Autre exemple de base avec milena.
* doc/examples/otsu: Petit programme Otsu.
* doc/examples/stats: Exemple de manipulation d'accumulateurs.


Voici deux exemples sous LaTex. Un jeu de test avec la confection de
vecteur et de matrices pour relater les forrmules connues en espace
3d. La version actuelle est dégradée par rapport à ce que j'avais pu
écrire. J'étais arrivé à la mise au point d'un extracteur de valeurs
propres mais je n'ai jamais pu retrouver cette version là, surement
une erreur sous svn. Le second document devait présenter la
documentation quick tour sous milena, mais j'avoue que c'est un
lamentable échec, je n'ai pas pris le temps de le faire. Je pense que
l'idée d'une documentation collaborative permettrait de répartir
l'effort.

* doc/formulae: LaTex directory.
* doc/quick_tour: LaTex directory.


XII ANNOTATING
--------------

Tout d'abord, voici les notes documentaires qui ont été réalisées sur
la problématique d'annotation d'image. On trouvera un fichier
class.txt qui a pour but de poser quelques réflexions sur les types de
classes de document. Les informations ne sont pas abouties mais
permettent de défricher un peu le terrain. Le document
syntheseMillet2008 est un compte-rendu de lecture des parties
relatives à nos travaux dans la thèse de Millet. Pour bien comprendre
mon travail, il est impératif de lire les travaux de Millet, ou
simplement ce compte-rendu. Le dernier document est moins intéressant,
il s'agit d'une note de travail sur les indicateurs de Millet bruts de
fonderie (testMillet2008). Cette note n'est ni achevée, ni
aboutie. Elle conclue sur le fait que les indicateurs et les seuils
donnés par Millet dans sa thèse sont complètement à revoir pour nos
besoins. Notemment, des tests sur la détection des images par rapport
aux cliparts nous ont convaincu que certaines images AFP contiennent
des de grandes zones homogènes qui induisent des erreurs dans les
prédicteurs de Millet. Néanmoins, les cas particuliers qui
contredisent les aspects opérationnnels de Millet n'enlèvent pas sa
réflexion: Les images noir/blanc (ou monochromes) ont une très faible
saturation, et/ou une forte concentration de la teinte. Les cliparts
ont une forte concentration de niveaux de gris autour d'un pic.

* doc/annotating: La documentation relative à l'annotation.


Après la lecture des descripteurs de Millet, un des premiers réflexe a
été d'en implémenter plusieurs pour voir ce qu'ils pouvaient ressortir
sur les images que nous avions. Le descripteur BIC sépare une image en
deux ensembles de pixels, les points intérieurs et les points
extérieurs. Les points intérieurs ont la propriété d'être de même
couleur que leur 4-voisins. Attention, la couleur est évaluée dans un
espace RGB à 3 bits.

* demo/annotating/bic: Histogrammes des points intérieurs et extérieurs.


Le descripteur LEP, lui, propose de seuiller par sobel l'image et de
faire l'histogramme des configurations du voisinage des points
seuillés. Pour ce faire, on utilise une convolution un peu spéciale
qui va attribué un unique id en fonction du voisinage.

* demo/annotating/lep: Histogramme des configurations des voisinages des pixels.


Un autre descripteur simple est le nombre de couleur dans une
image. Pour cela, il est possible de construire l'histogramme des
couleurs et de compter les cellules pleines. On peut éventuellement
appliquer une quantification sur l'espace des couleurs.  La
compilation laisse place à d'étranges warnings sur une comparaison
entre entiers signés et non signés, mais je n'ai pas la main dans mon
code (ou je ne sais pas comment faire) pour enlever ces warnings. Ils
sont récents, je n'avais pas souvenir de les avoir eu.

* demo/annotating/nb_color: Compte le nombre de couleurs dans une image.
* exp/annotating/nb_color: Adaptation pour fonctionner sur une base d'image.


L'histogramme RGB-64 est un descripteur simple qui quantifie les
couleurs sur 2 bits et réalise l'histogramme dans cet espace. C'est
bien sûr une classification gros grain, mais ajouté au reste ... La
version RGB-64-9 ajoute une phase de division de l'image en 9 sous
images. De cette manière, l'histogramme RGB-64 est construit sur les 9
sous images. Pour former le descripteur final, on fusionne les neufs
histogrammes.

* demo/annotating/rgb_64: Histogramme couleur dans l'espace RGB-64 (2 bits/axe).
* demo/annotating/rgb_64_9: Histogramme RGB-64 sur les 9 sous images.


Le descripteur de projection relaté par Millet est particulier. En
premier lieu l'image est sous échantillonnée pour réduire sa dimension
à 100 x 100 de manière à borner la taille des vecteurs obtenus au
final. Puis l'image est seuillée par sobel (threshold = 100). L'image
est d'abord divisée horizontalement en deux. Puis on établit la
projecton perpendiculairement à la séparation de manière à obtenir
deux vecteurs de 100 valeurs chacunes. On recommence l'opération en
divisant maintenant l'image verticalement. L'union des 4 vecteurs
forme le descripteur de projection. L'information condensée dans ces
vecteurs est simplement la répartition des contours de manière
horizontale ou verticale.

* demo/annotating/project: Répartition des contours horizontaux et verticaux.


La reconnaissance des cliparts s'appuie sur une analyse d'histogramme
qui est fournie dans le code suivant. L'idée est de dire qu'une image
de type clipart va être reconnaissable surtout à l'aide de ces
contours. La couleur existe mais est très grossière. Le faitde
dessiner à la main implique de simplifier énormément, de caricaturer,
le remplissage. Du coup, une analyse en niveau de gris de
l'histogramme révèle très peu de nuances. Il peut cependant en avoir
un peu. Néanmoins, il existe des logiciels pour aider à la fabrication
des cliparts qui proposent l'usage de dégradé, ce qui nuit à cette
méthode de reconnaissance. Millet analyze l'histogramme normalisé
(histogramme divisé par son pic) et regarde si son energie ne serait
pas concentrée autour du pic (5 pixels de chaque côté
maximum). Parfois cette méthode ne fonctionne pas correctement sur des
photographies qui ont un cadre uniforme. La méthode trouve un pic (le
cadre) et vérifie alors qu'une proportion non négligeable des pixels
sont bien autour de ce pic (tout dépend de l'épaisseur du cadre). Pour
palier à cet inconvénient, Millet propose d'utiliser ce test, non plus
sur l'image entière, mais sur chacune des 16 sous images après un
découpage géométrique régulier. De facto, la contribution du cadre
diminue suffisemment pour repasser en dessous du seuil de
reconnaissance.

* demo/annotating/stddev_color: Descripteur utilisé reconnaitre des cliparts.
* exp/annotating/stddev_color_16: Adaptation pour le travail sur base.
* demo/annotating/stddev_color_16: Descripteur pour cliparts avec 16 imagettes.
* exp/annotating/stddev_color: Adaptation pour le travail sur une base d'image.


A partir de maintenant, tous les morceaux de codes réalisés préparent
directement ou indirectement le résultat de la classification des
bases (exp/annotating/bench).

Plus de temps pour faire le code use correspondant aux fichiers
librairies. Tout le code pour le faire est dans hsv. Rien de
compliqué, mais allons à l'essentiel.

Le but du code HSV est d'effectuer les tests de Millet ou des
améliorations sur ces tests. Le premier test proposé par Millet est
l'achromaticité. Il s'agit de regarder s'il existe une faible
variation entre les trois canaux (R/G/B) pour un grand nombre de
pixels. Si c'est le cas, c'est que l'image est presque en niveau de
gris et peut être remplacée facilement par une image grisée sans trop
de distorsions au niveau de la couleur. Nous avons essayer de
généraliser un peu le test de manière à produire, non pas seulement
une réponse sur l'achromaticité de l'image, mais aussi avoir une vue
d'ensemble (sous forme d'image) des variations entre les cannaux pour
chaque pixel. Il n'est pas utile d'analyser les différences sur chacun
des canaux, prendre la différence absolue entre le canal min et le
canal max suffit pour définir le test d'achromaticité.

Les autres tests de Millet sont la faible saturation et la dominance
de la teinte. Pour savoir si la saturation est faible, il faut
utiliser un histogramme du canal dédié à la saturation. Si 95% des
pixels sont en dessous de 100, alors l'image est faiblement saturée,
elle est en noir et blanc. De la même manière, on regarde la dominance
de la teinte. Pour ce faire, il faut voir si l'histogramme de la
teinte ne possède pas un pic avec une très faible variance (tout
rapproché autour du pic). Si c'est le cas, la dominance de la teinte
est avérée et l'on peut calculé la couleur dominante. L'image est en
niveau de gris, mais colorisé autour d'une couleur (par cepia, vert
...).

Ce programme est très très sujet à changements, il m'a servit de test
et je ne peux pas juré qu'il est complètement sain au niveau du
traitement. D'autres versions sont potentiellement plus
stables. Notemment celle dans exp/annotating/hsv.

* mln/fun/v2v/rgb_to_achromatism_map.hh : Distance pour l'achromaticité.
* mln/fun/v2v/achromatic.hh : Define the achromatic map.
* mln/fun/v2v/hue_concentration.hh : Define the distance hue/peak map.
* mln/fun/p2b/achromatic.hh : Say if a site is achromatic.
* demo/annotating/hsv: Code des différents tests de Millet.


Dans le répertoire exp/annotating/hue, on trouve 3 fichiers textes qui
rassemblent des classes d'images. Tout d'abord les images ICDAR
n'ayant que du texte et des traces de couleurs (lettrine de couleur,
trait, petit bandeau), un fichier où il n'y a que du texte noir &
blanc et un fichier contenant les images couleurs (avec photographies
ou dessins). Cette classification a été effectuée de manière manuelle.
Le code hue test la proportion de pixels étant autour du pic de
teinte. Il s'agit de savoir si la dominance d'une teinte est
avérée. Le code renvoit la proportion de pixels agglomérés autour du
pic. Le but est de généralisé les tests de millets pour qu'ils se
ressemblent le plus possible.

* exp/annotating/hue: Implémentation de la généralisation du test de Millet.
* mln/fun/v2v/rgb_to_hue_map.hh : Construction de la map de teinte.


On retrouve les trois fichiers permettant de classifier la base ICDAR
en trois sous populations. Le test de saturation consiste simplement à
regarder si une certaine quantité de la population de l'histogramme de
saturation est en dessous d'un certain seuil. La généralisation du
test ne porte pas sur le test en lui-même, mais sur la forme dans
lequel le test est fait.

* exp/annotating/saturation: Implémentation de la généralisation du test.
* mln/fun/v2v/rgb_to_saturation_map.hh : Construction de la map de saturation.


Le test de value a déjà été décrit précédemment dans
stddev_color. L'idée est toujours la même, mais cette fois il est
effectué dans l'espace des valeurs (HSV). Cela ne change pas grand
chose, puisqu'il était utilisé sur des images en niveau de gris. C'est
l'un des tests importants car il réagit à la différentiation entre une
image type photographie et une image plus stylisée comme un
clipart. Ce test a aussi des vertus pour la distinction entre du noir
& blanc et de la couleur. Il s'avère que les images type photographie
avec pleins de couleurs ont un histogramme moins sujet aux pics que
les histogrammes noir & blanc. De facto, l'énergie de l'histogramme
est distribué sur l'ensemble de la plage contrairement aux images noir
& blanc où il y a une concentration de chaque côté de l'histogramme
(bipolarité).

* exp/annotating/value: Implémentation de la généralisation du test de Millet.
* mln/fun/v2v/rgb_to_value_map.hh : Transformation d'espace.


Le programme hsv reprend les tests préalablement élaborés auparavant
sur les plans H, S puis V. Il combine tout en un seul programme pour
avoir une vision plus synthétique de ce qui se passe sur les 3 espaces
simultanément.

Les tests incorpore mes transformations. C'est à dire que l'on
effectue une série de test équivalent à ceux de Millet (au moins dans
l'idée et le plus souvent, il s'agit d'une réecriture sous une autre
forme) en partant des histogrammes normalisés. Un histogramme
normalisé est un histogramme de flottant qui contient l'histogramme
classique divisé par le nombre total de pixels. En faisant cela, on se
déplace dans l'espace des distributions. Si l'histogramme n'a qu'un
seul pic et que ce dernier contient tous les pixels (pic de dirac par
exemple), alors l'histogramme normalisé donnera 1 comme valeur de
proportion à ce pic. En fait, l'intégrale d'une distribution vaut
1. Le but des distributions est de s'affranchir des caractéristiques
de taille de l'image, ce qui permet de comparer les histogrammes entre
eux. On peut ainsi comparer les histogrammes d'une photo AFP petit
format avec celui d'une image grand format de la base ICDAR. Le but du
jeu est de garder les idées de Millet dans ce nouvel espace. Les tests
obtenus sont équivalents mais pas identiques.

Pour la teinte, une fois l'histogramme normalisé obtenu, on cherche à
savoir s'il existe un pic avec une forte proportion de l'histogramme
autour de ce pic. Plutôt que le pic, nous prenons la moyenne qui est
un opérateur un peu plus robuste et nous calculons la proportion de
l'histogramme autour (un seuil donné en paramètre défini le périmètre
du calcul). L'expression sous forme de proportion plutôt que sous la
forme d'une variance rend le test homogène avec les autres tests.

Pour la saturation, après normalisation, on regarde la proportion de
l'histogramme en dessous d'un certain seuil. Il n'y a pas de
changement significatif par rapport au test de Millet. Le seuil
initialement proposé par Millet était 100, il a été adapté car nos
bases sont différentes des siennes (le notre est à 25).

Le test sur les valeurs (cliparts contre photos) a vraiment un intérêt
au delà de ce cas d'utilisation. Il nous renseigne sur la
concentration autour d'un pic de l'histogramme ou non. Nous préferrons
la mesure de similarité à l'équi-répartition des densités, mais l'idée
est exactement la même. Est-ce que notre histogramme est plat ou
inversement, est-ce que les contributions sont rassemblées autour d'un
pic? Si une image est noir et blanc, il existera un pic correspondant
au fond et la densité s'éloignera fortement de la distribution
équiprobable. Dans le cas maintenant d'une image couleur, la
répartition est plus homogène, couvrant un large spectre dans le
domaine de l'histogramme. Du coup, la distribution semblera davantage
equi-répartie. On notera que nous prenons le test à l'envers de ce que
propose Millet. Il essaye de voir si il y a un pic et calcule une
forme de contribution normalisée autour de ce pic. Nous au contraire,
on regarde l'absence de pic et on calcule la différence entre la
densité et cette absence de pic. Notre avantage par rapport à Millet
est démontré particulièrement dans les cas où il existe plusieurs
grosses distributions. A contrario, notre test souffre des cas où il
existe de nombreuses petites distributions.


Voici un premier retour sur les expériementations:
La discrimination entre la base AFP et la base ICDAR peut se faire en
étudiant la forme des densités des niveaux de gris.  Les images
naturelles semblent avoir un spectre recouvrant en général les 256
niveaux de gris alors que les images de documents ont une présence
importante du fond. Dans le cadre d'une densité, ce qui est alloué sur
le fond ne peut se retrouver ailleurs. Une comparaison avec la densité
équiprobable nous renseigne donc sur la nature des images.  Il semble
néanmoins qu'un certain nombre d'images défient ce dispositif.  Par
exemple des gros plans sur des zones mono-teintée (ski, voile,site
web).

* exp/annotating/hsv: Code unifiant les trois tests sur chacun des plans HSV.
* mln/fun/v2v/rgb_to_hue_map.hh : Transformation d'espace.
* mln/fun/v2v/rgb_to_saturation_map.hh : Transformation d'espace.
* mln/fun/v2v/rgb_to_value_map.hh : Transformation d'espace.


Le test sur l'achromatisme des images est décrit dans le code
suivant. Il a été purement et simplement abandonné dans la mesure où
c'est un cas très particulier qui est repris par une saturation très
faible. La saturation s'exprime comme 1 - min(channel)/max(channel),
mais dans le cas où le min(channel) == max(channel), la saturation
vaut 0. Le problème vient plutôt du calcul de la teine qui ne peut pas
admettre que le min soit égal au max. Pour ce calcul, on se débrouille
pour gérer le cas et renvoyer une valeur standardisée, Millet
proposait -1.

* exp/annotating/achromatism: Détection d'image couleur en niveau de gris.
* mln/fun/v2v/rgb_to_achromatism_map.hh : Transformation d'espace.


Ce programme a pour but de créer les histogrammes normalisés en rafale
pour les bases AFP et ICDAR. Il assure leur création dans les six
plans possibles R,G,B,H,S,V. De cette manière il est possible de
vérifier les corrélations éventuelles entre le canal B et G. Par
ailleurs, après visionnement de tous les histogrammes, on note des
spécificités dans les deux bases sur les plans S et V. Certaines
images ont des réactions très fortes sur le plan H, mais ce n'est pas
une caractéristique pour une base (seulement pour ces images en
question). Les résultats ont déjà été sauvegardés dans le répertoire
image du LRDE. Des infos sont notés à ce  sujet dans README.result. Le
seul but de ce calcul est de maîtriser csujet dans README.result. Le
seul but de ce calcul est de maîtriser ce qui se passe dans ces
espaces, pas simplement de supposer ce qu'il pourrait s'y passer. La
comparaison des images est rendu possible quelque soit la base
d'origine par le fait qu'elles sont normalisées. Chaque fréquence des
histogrammes est divisée par la somme des fréquences. On obtient donc
une version discrète des densitées. La somme des nouvelles fréquences
vaut 1.  On voit davantage si les densités se rapprochent d'une
équi-répartition ou non. La négative implique un ou plusieurs pics. Le
cas défavorable dans mon approche (qui existe pour certaines images)
est une multitude de tout petits pics autour de l'équi-répartition. Ce
n'est pas équi-répartie pour les calculs mais ce n'est clairement pas
la manisfestation d'une concentration de l'énergie quelque part.

* exp/annotating/histo: Creation des histogrammes normalisés.
* mln/fun/v2v/rgb_to_hue_map.hh: Transformation d'espace.
* mln/fun/v2v/rgb_to_saturation_map.hh: Transformation d'espace.
* mln/fun/v2v/rgb_to_value_map.hh: Transformation d'espace.


Dans le programme erreur, on teste l'idée de jonathan. Une référence à
ce sujet peut être trouvée dans README.img. Les bases AFP et ICDAR
sont retravaillées à l'aide de ImageMagick et de Gimp pour diminuer le
nombre de couleurs initiales. On oblige à n'avoir que 30, 20 ou 10
couleurs pour chaque base. Il y a donc 4 versions de chacune des bases
en comptant la version originale des images. Les algorithmes utilisés
par Gimp et ImageMagick sont très différents. L'idée de Jonathan était
de dire que lorsqu'une image est couleur, plus on réduit le nombre de
couleur, plus elle change vis-à-vis de l'image originale. Inversement,
si une image possède peu de couleurs (noir & blanc), sa dégradation ne
l'altérera pas tant que cela. Prenons une image d'un skieur de la base
AFP, en réduisant le nombre de couleurs, la combinaison marron va
devenir marron strictement homogène et la perception que nous en avons
est visuellement très altérée. A contrario, une image en noir & blanc
ne semble pas bouger d'un pouce. La comparaison avec la discrimination
sur la saturation ou la valeur montrera des résultats un peu meilleur
plus tard mais il impossible de préjuger a priori des résultats
futurs. L'erreur entre l'image initiale et l'image dégradée est
calculée avec le PNSNR (compression p278 Handbook Color). Le programme
calcule la dégradation et essaie de trouver automatiquement des seuils
de séparation pour les deux bases. 4 détection de seuils sont testées.
Ces seuils sont calculées avec deux bases représentatives des bases à
discriminer. En mode production, le seuil est vu comme une constante
pour le programme. Les deux premières classifications renvoient un
seuil calculée comme une moyenne pondérée des moyennes des populations
à discriminer. Le premier détecteur pondère par la déviation standard
et le second par la variance. Le troisième simule deux populations
gaussiennes de variances différentes et résoud l'équation de second
degré qui en résulte. Enfin, le dernier test ne préjuge pas des
distributions statistiques et réalise la minimisation de l'erreur de
classification. Pour cela, il suffit de compter le nombre d'images
bien classées et mal classées sur les bases d'apprentissage des
populations. On utilise pour cela la méthode Otsu. Le détecteur PNSRN
renvoie une valeur. Pour chaque population (AFP, ICDAR), on construit
l'histogramme de des valeurs obtenues. A noter, qu'il faut que les
valeurs du PNSNR soient ramenées entre 0 et 255. En pratique ce n'est
pas un problème, mais il faut le mettre en oeuvre, dans mon code, ce
n'est pas fait (les valeurs ne posaient pas de problème). Donc, pour
chaque seuil possible (de 0 à 256), on étudie la matrice de classement
(groupe 1 - détecté groupe 1, groupe 1 - détecté groupe 2, groupe 2 -
détecté groupe 1, groupe 2 - détecté groupe 2). L'erreur est
simplement la somme des quantités groupe x - détecté groupe y avec x
!= y. Finalement, pour chaque seuil, il est possible de connaitre
l'erreur. Le processus de minimisation de l'erreur revient à chercher
le seuil associé à l'erreur minimale. C'est ce dernier test que nous
préconisons. Il faut mettre en lumière que ces quatre tests renvoient
à peu près les mêmes seuils. La minimisation de l'erreur étant le
meilleur de tous puisqu'il minimise directement l'erreur de
classification et c'est ce que nous cherchions en fin de compte. Un
cinquième test a été fait avec une analyse de fisher sur l'histogramme
des populations mélangées, mais c'est une idée saugrenue car nous
disposons à ce niveau des populations séparées et évidemment les
résultats sont moins bons.

Petit rappel. Un vieux problème a été mis à jour ici. Lorsqu'on
calcule des informations sur un histogramme, le type temporaire qui
contient les résultats ne doit pas être le type qui encode les valeurs
des résultats. Par exemple, un histogramme de byte, un calcul de
variance tout simple où il faut stocker la valeur des pixels au carré
multiplié par leur occurrence tiendra facilement dans un long mais pas
dans un byte. Le sucre avec les acesseurs des itérateurs tend à
mélanger les genres. Une solution simple est de stocker la valeur de
l'histogramme dans un type pouvant effectuer les calculs et ensuite
retravailler avec ce type. Nous avions déjà discuté de ce problème et
je ne sais pas si tu avais pu corriger le problème. Si la
classification renvoit n'importe quoi, il se peut que cela provienne
de ce problème. Le problème ne se voit pas sur des calculs de
moyennes, il ne s'observe que sur certains calculs de variance (dépend
de la formule utilisée).

* exp/annotating/error: Test de l'idée de jonathan (dégradation des couleurs)


Le travail dans bench.cc reprend toute sorte de travaux déjà réalisés
dans d'autres fichiers. Il a pour but de comparer ensemble tous les
descripteurs pour la reconnaissance de base de données entre l'AFP et
l'ICDAR.

Le travail commence avec un certain nombres de routines travaillant
sur les histogrammes permettant de trouver le pic, la moyenne, la
variance et d'autres éléments. Les routines étaient éparpillées dans
le code, du coup je les ai regroupées au même endroit. Il y a des
redondances de code correspondant à des copier/coller ou à différents
essais. Prendre les versions les plus génériques et en faire des
accumulateurs serait un riche idée.

Huit détecteurs sont comparés ensembles:
- hue1, détection d'un pic de teinte très dense par la méthode de Millet.
- sat1, détection d'une densité importante dans les saturations basses (Millet).
- lvl0, comptage du nombre de niveau de gris (idée de Millet).
- hue0, détection d'un pic de teinte par la méthode des densités.
- sat0, détection d'une forte basse saturation par la méthode des densités.
- val0, détection d'un pic de niveau de gris par la méthode des densités.
- val1, détection d'un pic de niveau de gris par la méthode de Millet.
- err, PNSNR (idée de jonathan).

FIXME: Attention, le PNSNR n'est pas borné, il faut le faire, il doit avoir
au maximum 255 comme valeur.

Tous les détecteurs ont été expliqués en large, en long et en travers
dans les sources précédentes. LIRE le chapitre XII (ANNOTATING) de ce fichier
en entier.

Ensuite vient les séparateurs de population statistiques qui ont été
déjà introduit dans le fichier error. Bien que tous soient présent,
c'est la minimisation de l'erreur qui est utilisée.

Enfin vient le front end, l'un des plus complexes que j'ai écrit cette
année.  Le main lui même, n'est pas la partie la plus complexe. Il
définit les actions fonctionnelles à réaliser et la structure de
donnée réalisée pour garder la trace de tous les résultats.
- File_name : Cette variable retient le nom des fichiers. C'est un tableau
de la taille du nombre d'images rencontrées toute base confondue. Comme on
ne parcourt qu'une fois les répertoires, il faut pouvoir retenir cette
information qui servira éventuellement pour la nomenclature des dumps
par la suite.
- Result : Cette variable contient toutes les informations du traitement.
C'est un tableau à deux dimensions, une pour les images et une autre pour
les descripteurs. L'index d'image est le même que pour file_name.
- Size : Cette variable contient le nombre d'images par database.
- Threshold : Cette variable va stocker les seuils calculés sur chacun
des descripteurs. Ces seuils sont sensés effectuer la séparation entre les
deux bases.
- Cxx : variables de comptage des images bien ou mal classées relativement
à la position des seuils et à l'appartenance d'origine des images. Cette
appartenance d'origine est calculée à l'aide Size qui contient le nombre
d'image par base de données. Comme les images sont vues dans l'ordre, les X
premières appartiennent à la base ICDAR et les Y suivantes à la base AFP.
- histo : Variable servant à effectuer par database et par descripteur un
histogramme utilisé ensuite lors de la discrimination des bases.

La partie compute_descriptors a pour mission de passer une fois sur
toutes les images et de calculer les descripteurs associés. A l'issue
de cette passe file_name, result et size sont remplis et pourront être
utilisés par les autres routines.

La partie dump_descriptors a pour but de réaliser un tracé en gnuplot,
avec une couleur différente pour chaque base. Le graphe montre les
valeurs utilisées par chaque descripteur pour toutes les images de la
base.

La partie correction des descripteurs est optionnelle et force un
certain nombre de valeurs pour être inférieures à 256. Le but était de
pouvoir travaillé, même si les descripteurs n'étaient pas complètement
opérationnels. Elle sert donc pour le debug.

La partie calcul des histogrammes sert à obtenir la distribution des
valeurs de chacun des descripteurs en fonction des bases
utilisées. C'est une étape préliminaire à l'analyse des populations et
au calcul des seuils.

La partie calcul des seuils repose sur la minimisation des erreurs de
classification. Cette méthode ne fonctionne bien si la classe zéro à
une moyenne inférieure à la classe un. Du coup, il n'est pas possible
de déterminer de manière simple si la classe 0 correspond à l'AFP ou à
l'ICDAR. Pour chaque descripteur, les cartes sont rebattues.

Enfin, tous les histogrammes sont sauvés pour pouvoir comprendre et
visualiser les résultats.

Le main2 ne sert à rien, juste pour des essais.

Attention, modification VAL0/VAL1, vérifiez que le bon descripteur est
au bon endroit dans le tableau.

* exp/annotating/bench: Comparaison des détecteurs pour la classif. ICDAR/AFP.
